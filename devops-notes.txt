8th sep 2025 : 

Linux ?

it's os , 

it's opensource os , having multi destros 


taking command and gives the output on terminal 



======================


Linux --> linus Torvalds  --> 
unix --> 

git 

it's an opensource  operating system, it has both text and graphical based operating system 


it's for free 


merits : 

it's open source , 


security : 

stability and reliability : 

package mgt   -> apt snap dpkg , 


==============

software compatibility 

driver support : 

user interface and desktop environment 

learning curve : 


==================================================================


fedora and ubuntu 
amazon Linux 


2 Linux distros or distributions or flavours  Families 


1.debian Linux distribution family 
2.fedora Linux distribution family 


1.debian Linux distribution family   -> apt or apt-get  or dpkg 
Debian 
ubuntu
kali 

2.fedora Linux distribution family --> yum or rpm 
fedora
amazon Linux
cent os 


snap 

zypper -> openSUSE 

package mgt 

in k8s 


distroless 
alpine  fedora or 
busybox apt
scratch 



apt install -y git


in mac os : 

brew --> 

===========================================


sudo --> admin or root access or 



sudo <pkg mgr> <install>/uninstall/update   <tool> -y 

sudo apt install git -y 

=======================


what is Linux directory structure and purpose of each directories ?
create github account and fork the repo 
============================================
usage of linux

Merits of Linux:

Open Source:

Merits: Linux is open-source, meaning its source code is freely available and can be modified and distributed. This fosters collaboration and community-driven development.

Benefits: Users can customize the operating system to suit their needs, and security vulnerabilities can be addressed more rapidly.


Security:

Merits: Linux is known for its robust security features. Its multi-user environment and permissions system help protect against malware and unauthorized access.

Benefits: Linux is less susceptible to viruses and malware compared to some other operating systems, making it a preferred choice for servers and critical infrastructure.

Stability and Reliability:

Merits: Linux is known for its stability and reliability. It can run for extended periods without needing to be rebooted, making it suitable for servers and critical systems.

Benefits: System crashes are less frequent, and the system tends to handle heavy workloads efficiently.


Performance:

Merits: Linux generally performs well, even on older hardware. It can be configured for specific use cases, making it efficient for various applications.

Benefits: Linux is often used in resource-constrained environments and can provide good performance for tasks ranging from desktop use to server applications.


Package Management:

Merits: Linux distributions use package managers that simplify software installation, updates, and removal. This centralized approach ensures software is installed with dependencies, reducing compatibility issues.

Benefits: It's easier to manage software and keep the system up-to-date.

Demerits of Linux:
------------------

Software Compatibility:

Demerits: Some proprietary software and applications are not available for Linux. Users may face challenges finding alternatives or using compatibility layers like Wine.

Drawbacks: Gaming and certain professional applications may have limited support on Linux.

Driver Support:

Demerits: While Linux supports a wide range of hardware, some manufacturers may not provide Linux drivers. This can lead to compatibility issues for specific devices.

Drawbacks: Users may need to rely on community-developed or generic drivers, which may not offer the same level of performance or features as official drivers.

User Interface and Desktop Environments:

Demerits: The variety of desktop environments and user interfaces in Linux can be overwhelming for new users. It may take time to find one that suits individual preferences.

Drawbacks: The user experience may not be as consistent as in some other operating systems.

Learning Curve:

Demerits: For users accustomed to other operating systems, the Linux command line interface can be intimidating. Learning the commands and system configurations may take time.

Drawbacks: The learning curve can be a barrier for some users, especially those who are not familiar with the command-line interface.

Limited Support for Certain Software:

Demerits: Some industry-specific or niche software may not have Linux versions or equivalents. This can be a significant drawback for professionals in certain fields.

Drawbacks: Users may need to resort to virtualization or dual-boot setups to run essential software that is not natively supported on Linux.

===============================


linux distributions :

2 linux distribution families:

1.debian family

2.fedora family

1.debian distribution family ( apt or apt get  )
debian
ubuntu 

2.fedora distribution family ( yum or dnf )

fedora
kali  ->
open suse
Redhat linux 
cent os
alma linux

amazon linux 2023
amazon linux 2 

alpine -> apk 

package mgt tool 

update, upgrade, install, unintall, 






















linux distributions 


2 types of linux distribution families

1.debian  linux distribution families  -> apt  or apt-get 
2.fedora  linux distribution families  -> yum 

1. debian linux families  -> apt install git -y
debian  
ubuntu 

2.fedora family
fedora
centos
opensuse
amazon linux 2    -> yum install git -y  
kali linux
alma linux

alpine linux ->  independent linux distribution , apk -> apk install git -y 
busy box -> light weight linux distro for linux utilities .
scratch 



-----------------------------------------------------------------------------------------------------------------------------

linux os

os -> combination  of shell and kernal 

it's an interface user and system


kernel it's software , it's heart  of operating software , core component of os 

linux os depends on kernel 

system depends os 



html
source code  web application   webserver

home.html 
<html>
<body>
<h1>manjuTechPvtLtd</h1>
<p> this is software solutions </p>
</body>
</html> 


sample.py 

a="welocome  to linux"
print(a)


computer  , 

.java
.py 

execution 

jvm
pvm 
jre 

a=10
print(a,type(a))

source code  compiling             compliler                                                    pvm                            
    py                             .pyc,javac , complied code or byte code           processor/ram/rom
                                









programming execution process

 
                 compiling phase                                executing phase                 pvm /jvm  /processor/cpu      
sample.py                             compiler    
                                      compiled code                                                   +v 0,1 
                                      byte code (pyc,javac)                                            o  













ls  -> listing the files and folders


ll   -> longlist files and folders






source code : 





Linux Shell:
- default shell in Linux is BASH.


 in os there is a special program is called "shell".
- shell is interpretor
- shell takes the commands from user and execute it.
- and it will gives the result as user understandable.

linux kernal  


linux distributions




amazon linux 2 -> rpm , snap , yum ,dnf

linux package mgrs with different linux flavours  

APT (Advanced Package Tool) - debian, ubuntu
DNF (Dandified YUM) or yum (older version)   - fedora, redhat,centos,
Zypper - pkg mgr to openSUSE   -> sudo zypper install git -y
Snap -> pkg mgr to debian and fedora as well 
RPM (Red Hat Package Manager) -> fedora,centos and so an
DPKG (Debian Package) -> debian and ubuntu



RPM VS YUM 

RPM -> ONLY TOOL, not going to install dependencies with it 
Yum

git pythons




RPM VS YUM 


brew (Homebrew package manager) -> mac os --> sudo brew intall git 

macOS: Command(cmd)  (⌘) + C  -> copy the files  ls,ps,rm, mv ,cp,

Standard: Ctrl + C  -> copy the files 

port ( MacPorts package manager) -> mac os -> 

sudo -i or sudo su -  --> to get into root user


==================================================================================================================================
LINUX FILE/DIRECTORY /FOLDERS STRUCTURE
--------------------------
most essential directories path and devops tools which are stored in it,  that should devops remember, cos where all executable files and storage directories


/ (root directory):

The top-level directory in the Linux file system hierarchy.
All other directories are subdirectories of the root directory.
---

🗃️ /bin: Binaries - This directory holds the essential user command binaries that all users can access.

Contains essential binary executable files accessible to all users.
Common commands like ls, cp, mv, yum apt,rm, etc., reside here. sh

---
⚙️ /etc: System Configuration - Houses the system configuration files, acting as the control panel on Linux.

Contains system-wide configuration files.
Important files like passwd (user account information), hosts (DNS resolution), sudoers (sudo configurations), and group more.
---

🏠 /home: User Home Directories - Contains the home directories for users and other accounts.
Home directories for regular users are located here.
Each user has a subdirectory with their username.
---
📁 /var: Variable Files - This is the variable data directory storing changing data like logs, mails, print spools, etc.
and journalctl -> to check the log files in your local machine or system .

Contains variable data files, such as log files (/var/log) and mail (/var/mail).
Also includes temporary files, caches, and other variable data.
---
👥 /usr: User Binaries - Contains multi-user utilities, applications, and libraries.

Contains user-related programs and data, usually read-only data (except for /usr/local).
Common directories within /usr include /usr/bin, /usr/lib, /usr/share, etc.


git 

git add 

ls 

/bin/bash
usr/bin/bash


---

🔧 /sbin: System Binaries - Contains the essential binaries used by the system administrator for system maintenance and troubleshooting.

Similar to /bin, but it contains essential system binaries for the root user (administrative commands).
Commands like fdisk, ifconfig, reboot, etc., are stored here.
---
🎁 /opt: Optional Software - Stores optional or additional software from vendors.
cd /opt -- installing the tools ,sonarqube,tomacat, nexus and so on

Typically used for the installation of optional (third-party) software.
Some software packages, especially those not installed via the package manager, might reside here.
--
🔨 /srv: Service Data - This directory contains server-specific services related data.

Contains site-specific data served by the system.
For example, web server files(nginx)can be stored here.
---
🗑️ /tmp: Temporary Files - This directory stores temporary files created by the system and users.

A temporary directory accessible to all users, where they can store temporary files.
Files in this directory are usually deleted upon reboot.
---
📊 /proc: Process Information - A virtual directory detailing system and process information.

A virtual filesystem that provides information about running processes and system configuration.
It's not a real directory with disk storage but rather a dynamic interface.
---


💽 /dev: Device Files - Home to all device files, such as hard disks, USB, CD-ROM, etc.
null file 

Contains device files that represent hardware devices on the system.
These files are used to interact with hardware components.
Remember, these are just some of the essential directories. Linux has a vast file system hierarchy, and depending on your specific tasks and the distribution you are using, you may encounter additional directories or variations in their organization. Understanding these directories and their purposes will provide a solid foundation for your work as a DevOps engineer.

------

📚 /lib: System Libraries - Houses library files that are needed by the system and the users.

📝 /mnt: Mount Directory - Used for mounting other temporary file systems.

💿 /media: Removable Media - Acts as a temporary mount directory for removable devices.

🚀 /boot: Boot Files - Contains boot loader related files.

👑 /root: Root Home - This is the home directory for the root user.

🔌 /run: Application Information - A tmpfs file system that contains application information.

🧑‍🔬 /usr/local: User Local - Contains user's programs that are installed from the source.

📦 /lib64: 64-bit Libraries - This is where the 64-bit library files are stored.



==================================================================================================================================


give all devops tools and  their directory path in linux 

there are numerous DevOps tools available, and they can be installed in different locations in the Linux file system. The following is a list of some popular DevOps tools along with their common installation paths:

tools -> executable path /bin and configuration path /etc


Git 

Path: Usually installed system-wide, binaries in /usr/bin/git and configuration files in /etc/gitconfig.
User configuration: ~/.gitconfig.

Ansible 

Path: Executable located in /usr/bin/ansible.
Configuration: /etc/ansible/ansible.cfg.
Playbooks and inventory files  can be stored anywhere, often in the user's working directory.


Puppet

Path: Executables located in /opt/puppetlabs/bin.
Manifests and modules are stored in /etc/puppetlabs/code.

Chef 

Path: Executables located in /opt/chef/bin.
Cookbooks and related files are stored in /etc/chef or /var/chef.


Jenkins  -> /var/lib/jenkins/workspace

Path: The installation path may vary, but commonly found in /var/lib/jenkins.
Configuration: /etc/default/jenkins or /etc/sysconfig/jenkins.

Docker

Path: Executable located in /usr/bin/docker.
Docker images and containers are stored in /var/lib/docker by default.

Kubernetes (kubectl)

Path: Executable located in /usr/bin/kubectl.
Configuration: ~/.kube/config.

Terraform

Path: Executable located in /usr/bin/terraform.
Configuration files can be stored in any directory, commonly in the user's working directory (terraform.tf, variables.tf, etc.).

Prometheus

Path: Executable located in /usr/local/bin/prometheus.
Configuration: /etc/prometheus/prometheus.yml.

Nagios

Path: Executables and configuration files are commonly found in /usr/local/nagios or /etc/nagios.


Grafana

Path: The installation path may vary, but commonly found in /usr/share/grafana.
Configuration: /etc/grafana/grafana.ini.

ELK Stack (Elasticsearch, Logstash, Kibana) in AWS

Path: The installation paths may vary, but configuration files and data are typically stored in /etc/ or /var/.\

==================================================================================================================================
NAVIGATION AND DIR CONTROL COMMANDS 

man -> manual page 

--help




$ -> normal user  -> id -u  -> 1000

sudo -i  or su -

# -> root user or admin user -> id -u  -> 0


exit -> to go back to normal user or logout from root user 


. 
..

/


ll -> longlist of the files and directories 
ls -ld */   -> to list only the directories in a directory in Linux

ls -> list of all the files and directories but it doesn't show the hidden filesc(. or ..files/dir) and folders
ls -a -> list of all the files and directories along with  hidden files and folders
ls -l -> longlist of the files and directories
ls -id <name of dir> -> to display the particular dir 
ls -lh -> list out the all files and directories with size 
ls -lR   -> to list the all folder with subfolders 
ls -lh  .txt     -> to see the size of a file 
ls -i    -> inode values
ls -iltr -> full inform of files and dir with inode values
man ls -> 
ls -> to list the files and dirs in the local machine
ls -l -> to display the longlist of  default files and dir
ll    -> to display the longlist of  default and hidden files and dir
ll -h -> to display the longlist of  default and hidden files and dir with their size , -h ( human readable format )
ls -ltr  -> to display the longlist of  default files and dir, sort by time  with reversal order
ls -lt   -> to display the longlist of  default files and dir, sort by time
--------

touch command

touch < file name >   -> to create a empty file
touch filename{1..30} -> to create multiple files


---------
echo command : to print or to display the  line ( of content )

echo "some content" > samplefile.txt   -> creating a file with content , the content is redirecting or replacing . 	
echo 'hello world' >> samplefile1  -> creating a file with content , the content is appending 

echo -e '#!/bin/bash\necho "Hello world"\nthis is third line ' > sample.txt   

-> here you used single quote and double quotes, so this is how creating script with some content .      \n -> new line , -e -> 


echo >> org1.txt hello        -> creating a file with content
echo <name of file >          - to display or print the output  of executable file 
echo -n > newfile1.txt     ->  to make file empty ( existing file with content)


---------
cat command 

cat -> to display the content of file

cat /etc/shells -> to display the default shells in your local machine

cat >> file1.txt --> interactive mode , appending the content 
cat > file1.txt --> interactive mode 

cat file1.txt>file2.txt     -> to redirect the content from one file to another existing or new file ,

cat id_rsa.pub > authorized_keys

cat file1.txt >> file2.txt  -> to appending the content from one file to another existing or new file


file1
file2 

file3 


cat file1 file2 > file3   

vim   
  
---------
mkdir command   -> 

mkdir < dir > --> to create the dir

mkdir day{1..40}      ->  to create multiple dir


mkdir -p <maindir>/<subdir>  

mkdir dir1 && cd dir1  -> used to create and switch to the same dir ,

mkdir dir2 && touch dir2/file1.txt   -> to create a folder and create new file in the same folder (..)

mkdir dem6 && echo "my fourth demo session" >> dem6/file5.txt    -> used to create new dir with content file 

1.1.2.

incremental changes in version is called upgrade 


&& and | 

-----

rm commands 


rm  --> to delete/remove  the file 

rmdir <dir>  --> to delete the empty dir only

rm -i <file name >   -- it's going to ask user to confirmation before removing the files ( yes/y or no/n )

rm -R <file name >/dir  --> to delete the dir recursively 

rm -rf <dir>  --> to delete the dir with content

rm -rf file_name 


---> dec-15 --------------------------------------


| -> Temporary storage  and && -> 

&& -> to run the multiple commands on terminal 






journalctl | tail -n 3 

---------
cd commands  :

cd -> used the changing the dir
cd or cd ~ --> to go back to home dir
cd - -> used to go back recent worked dir, the dir which u entered most recently 
cd .. -> used to go back previous dir
cd ../.. -> it takes you to previous dir, with two steps back 

--------

--------

mv command  


mv < old file>  <new file>

dont have particular command for rename the file or dir 

mv 

mv --> used to move the file/dir from one dir to another dir and also used to rename the file/dir
--------

cp command -> to copy the files or content of file or dir form source point to destination point 

cp 
-----------------

networking commands :


httpd webserver

html files/css files  to create web pages - webserver http/nginx


publicip:90
publicip:90
publicip:89



https  : 443

http : 80

system 
httpd : 80
tomcat 8080
nginx : 80

jenkins : 8080



grep/find/cut/sed/awk


hostport:containerip
8989:80   -> amazon.com
8983:80   -> aws.amazon.com
79908:80  -> shopping.amazon.com



nginx:80

amazon.com   8888: 80            47477
aws.amazon.com 9989: 80             8484
shopping.amazon.com  8848:80       448

--------------------------
process mgt commands 

ps



ps -ef  OR ps aux   ->  detailed list of all processes running on the system,



ps aux | grep nginx    -> Filter Processes by Name

sudo lsof -i :80    -> This command is used to list information about files that are currently opened by processes.

sudo kill PID

sudo kill -9 PID   --> -9 (forcefully)

top : to display linux tasks and running process 

sar : ( system activity report ), used to collect the CPU,MEMORY AND I/O usage  (not found in bash shell )



---------------------------------------------------------------------------------------------------
wc     -> wc/word count used to count the lines words and characters in a file

manjunathachar@manjunathachar-k-t:~$ wc var1.sh 

 19  40 260 var1.sh
 
 
 wc -L  var1.sh     -> display the big line or longest line or line lenth in  file 
 
 cat -n file.txt     -> to display the file content in chronological order,
 
 tac file.txt.sh  -> to display the content of file in reversal order
 
 
more file1.txt     -> to display more information of particular file , can tab in lapltop

ex: the file which conatains 1000 lines , 501th 



more -s  file1.txt     -> to surface the content in the file or remove the space or gap in the file 

more +40 file1.txt    -> to start the files from line number 40 in the file 

less file1.txt     -> to start the files from line number 40 in the file , to display big file we use less command

head file1.txt or head -n 5 file1.txt     -> used to print 1st 10 lines of the file , we customised based on changing the numbers

tail file1.txt       -> to get last 1o lines of the file 

/var/toolname/filename/

journalctl | tail
-------------------


User/Group Administration commands

Note: Old password is first requested then new password is requested twice for confirmation.

use sudo or root access to execute commands 

useradd(debian) or adduser(Fedora)  -> creates a new user a/c -> only root user can execute this command 
  
passwd : changes a user's passwords

cat /etc/passwd :  To view a list of users on a Linux system,


sudo useradd username -> Creating a User


sudo passwd username   -> Setting Password for a User:


sudo userdel username   -> Deleting a User:

Creating a Group:   

sudo groupadd groupname   -> creating group 

sudo groupadd developers

sudo usermod -aG groupname username    -> Adding or appending  a User to a Group 

sudo gpasswd -d username groupname    -> removing a user from  a specific group      


sudo usermod -d /new/home/directory username  -> Changing a User's Home Directory:


sudo usermod -s /path/to/new/shell username  -> Changing a User's Shell:

sudo usermod -s /bin/bash john


sudo groupdel groupname  Deleting a Group:

sudo groupdel developers


cat /etc/group   -> Listing Groups 


id -> it's one more command which will show the user details such as his primary group and his secondary group.

$  -> id -u -> 1000  -> normal user 
#  -> id -u -> 0   -> root user 

su -> to switch user and to come out from the user press CTRL+D,logout or exit.

----------------------------------------------------------------------
chmod command--> change mode 

alpha/num 

there are two ways to give permission to the user or group or others to access the files or directories

drwxrwxr-x  3 manjunathachar manjunathachar 4096 Feb 26 17:15 newdir/
-rw-rw-r--  1 manjunathachar manjunathachar  138 Feb 26 17:48 sample.txt


alpha
number   0 to 7

- 
r- read -> 4
w - write -> 2
x - execute -> 1 
               7
- = 0

user                        group                           other
r  w  x                    r w x                              r - x 
4  2  1                    4 2  1                             4 0 1
7                            7                                    5


5            6        4  
r-x         rw-       r--



chmod 564 sample.txt





chmod 300 roboshop 
d -wx --- ---


chmod 563 roboshop 

d r-x rw- -wx
  
chomd 400 pem.file 
-r-- --- ---


        file or dir     user   group   others
alpha-    -  or d       R W X  R W X   R W X
num -                   4+2+1  4+2+1   4+2+1     ( 0 to 7)  
group   others
alpha-    -  or d       R W X  R W X   R W X
num -                   4+2+1  4+2+1
                          7      7       7         

"-" > that's not allowed to access the files and folders 

file1 


- -wx rw- ---   username groupname  sizefile  file created date and time   file name


  021 420 000
  3    6   0  
  
  chmod  360 filename
  
  
------------------------------------

Remote Access Commands

SSH (Secure Shell):   -> Connect to a remote server

ssh username@remote_host 



SCP (Secure Copy):   -> Copy files between local and remote systems securely: jenkins publish over ssh -> 

chmod 400 my-aws-key.pem

scp /path/to/local/file username@remote_host:/path/to/remote/destination   -> one server to another server

scp -i /path/to/your/keyfile.pem /path/to/local/file username@ec2-instance-ip-or-dns:/path/on/ec2  -> local machine to aws-ec2


scp -i "k8s-project.pem" /home/manjunathachar/var1.sh ec2-user@ec2-184-169-248-88.us-west-1.compute.amazonaws.com:/home/ec2-user


scp -i "your pem file" <local server's directory path> <remote server's directory path>

scp -i "amazon-linux2.pem" /home/manjunathachar/sys-update.sh ec2-user@ec2-44-223-65-183.compute-1.amazonaws.com:/home/ec2-user

by default the pem has 664  private key 

r -> 4
w -> 2
x -> 1

0 to 7 

- --- --- --- 
  rwx rwx rwx
  421 421 421
   7   7   7 
   
   alpha
   number
   
 -   r-- --- ---
 f   4    0   0
   
 chmod 400 
   
   
   
   
  cp
  



scp -i "my-aws-key.pem" ec2-user@ec2-34-207-173-221.compute-1.amazonaws.com:/path/on/ec2/var1.sh /path/on/local/machine  --> copy the files from ec2 to local machine.




scp -i "my-aws-key.pem" ec2-user@ec2-34-207-173-221.compute-1.amazonaws.com:/home/ec2-user/robo-shop /home/manjunathachar/linuxdemo/newdemo1



telnet : Connect to a remote server (less secure than SSH, often not recommended):

telnet remote_host

ssh -i username:remotehost


----------------------------------------------------------------------
Hardware Information Commands :

free : To find the amount of free and used RAM memory in the system.

du -> 
df



sonarqube , maven , 2 4 ram required , 2 , 4 cpc ,


dmidecode -t 17  -> It give the RAM information like type of RAM(SD RAM, DRAM or DDR/2/3),Speed , Manufacture etc -> root user can perform this command 

vmstat: it will gives the virtual memory statistics .


System resource commands 

Man -> manual page , metadata of the linux utilities 

who -> displays the current user working on the system

w -> show who is logged on and what they are doing

users : displays a compact list of the users currenly logged on the system

whoami : display the current user info who gave this command

whereis -> path/locate the binary, source and manual page for a command

date -> print or set the system date and time

df ->   for entire system   report file system disk space usage -> displays the local disc drive , ssd, hdd 

du -> for fils or dir estimate file space usage, it displays the detailed information of file and folder usage

du -sh < dir name >   -> to see the size of directory   ( -s summarise the files and folders ) , 

hostname -> show or set the system host name ,in ec2 instace -> private ip of instance 

ifconfig or hostname -i or ip a  -> to find the ip address 

whatis ls

uptime -> how long the system has been ruuning 

last  -> show listing of last logged in users 
last root -> to get the most recently logged in as root users
sudo lastb ->  to get the list of all bad log ins in your local machine
  


systemctl start <name of service >    ---> debain/ubuntu/fedora 

service <name of service > start      ---> in  redhat/centos

systemctl -> used to check the running services in your local machine

systemctl --failed   -> used to get the failed service in the system

systemctl start <name of service >  to start the service (prometheus service)
systemctl restart <name of service >  to restart the service (prometheus service)
systemctl reload <name of service >  to reload the service (prometheus service)
systemctl daemon-reload  ->  whenever you make any changes in system config file , have to reload or restart the systemd or system daemon  
systemctl status <name of service >  to check status of  the service (prometheus service)
systemctl enable <name of service >  to enable  the service at boot,  (prometheus service)
systemctl stop <name of service >  to stop the service (prometheus service) 
jounalctl -> to get systemlogs 



chown -> changing ownership 

chown username <file or dir name >


----------------------------------------------------------------------

Archive/Data Backup Commands :

zip -> If you have a bunch of files and folders and want to compress them into one archive, use zip

zip archive.zip file1 file2 directory1  -> Command to Create a Zip Archive:

unzip archive.zip -d destination_folder ->  unzip archive.zip -d destination_folder

----
gzip ->  If you want to compress a single file, use gzip.

gzip file1  -> Command to Create a Gzip Archive:

gzip -d file1.gz   ->  Command to Extract a Gzip Archive:


rsync 

---

tar -> tape archive used  to compress, archive and store files and directories in local machine

-c --create Create a new archive.
-x --extract Extract files from an archive.
-t --list List the contents of an archive.
-f --file=ARCHIVE Use archive file or dir ARCHIVE.
-v --verbose Verbosely list files processed


cvf  ./name of archive file.tar  ./name of file or dir    --> to create tar file

tar -cvf archive.tar file1 file2 directory1


tar xvf name of archive file.tar  -->  to extract the tar files




====================================

Networking commands :


manjunathachar@manjunathachar-k-t:~$ ip address show or ifconfig   -->  to see the ip address 

ip route  or route --> default gateway 

netstat  -rn  --> same as route 

nmcli   --> to see dns resolver 

cat /etc/resolv.conf   --> to see the aws name server .

to find the remote network information like its ipaddress , routes , system online or not 

dig google.com 

nslookup( old command)   --> same as dig to get ipaddress of remote network

to check the route , how it's routing, how many hops it's going to hit to reach the destination .

traceroute google.com   ( install traceroute -> sudo apt-get install traceroute)

Traceroute is a network diagnostic tool used to trace the route that network packets take from your computer to a destination host or server on the internet.

This is a traceroute command showing the path and response times of data traveling from your computer to Google's servers. Each line represents a different network device (like routers) the data passes through each hops


manjunathachar@manjunathachar-k-t:~$ traceroute google.com
traceroute to google.com (142.250.205.238), 30 hops max, 60 byte packets
 1  192.168.0.1 (192.168.0.1)  8.222 ms  8.835 ms  13.865 ms
 2  103.139.156.142 (103.139.156.142)  13.973 ms  14.062 ms  14.489 ms
 3  103.139.156.141 (103.139.156.141)  23.208 ms  23.219 ms  26.620 ms
 4  103.42.72.34 (103.42.72.34)  46.791 ms  46.776 ms  46.760 ms
 5  * * *
 6  142.250.228.186 (142.250.228.186)  32.184 ms 142.251.49.218 (142.251.49.218)  28.109 ms 142.251.55.62 (142.251.55.62)  25.946 ms
 7  108.170.253.105 (108.170.253.105)  25.884 ms 108.170.253.106 (108.170.253.106)  35.950 ms 142.251.60.187 (142.251.60.187)  23.798 ms
 8  maa05s28-in-f14.1e100.net (142.250.205.238)  27.270 ms  27.457 ms 74.125.242.129 (74.125.242.129)  24.770 ms
	
	
	
ping google.com --> ping is , to check whether remote server working or not , it's used to check the remote network connections 	
	



--------
history command

history
history -c

To delete the last 10 commands from your shell history

history -d $(history | tail -n 5 | awk '{print $1}' | tr '\n' ' '); history -w



--------

text editors commands :
----------- 
 vi or vim 
 nano  
  
  
vim editor 
vim file
i or insert key -> insert mode
esc -> command mode
esc -> :q! -> exit  without saving the file
esc  -> :wq! -> to save and exit from the file 
esc -> shift +zz -> to save and exit from the file

--
Normal Mode Commands:
Moving the Cursor:

h: Move cursor left
j: Move cursor down
k: Move cursor up
l: Move cursor right
Example: Press h to move the cursor left.

Navigation:

w: Move to the beginning of the next word
b: Move to the beginning of the previous word
gg: Move to the beginning of the file
G: Move to the end of the file
Ctrl + u: Move half a page up
Ctrl + d: Move half a page down
Example: Press w to move to the beginning of the next word.

Editing:

i: Enter insert mode before the cursor
a: Enter insert mode after the cursor
o: Open a new line below the current line and enter insert mode
O: Open a new line above the current line and enter insert mode
x: Delete the character under the cursor
dd: Delete the current line
yy: Copy the current line
p: Paste the copied or deleted text after the cursor
u: Undo
Ctrl + r: Redo
Example: Press i to enter insert mode before the cursor.

Search and Replace:

/pattern: Search for a pattern

Example: Type /pattern and press Enter to search for a pattern.

n: Move to the next occurrence of the search pattern
N: Move to the previous occurrence of the search pattern
:s/old/new/g: Replace all occurrences of "old" with "new" in the current line
:%s/old/new/g: Replace all occurrences of "old" with "new" in the entire file



Saving and Quitting:

:w: Save changes
:q: Quit
:wq or ZZ: Save and quit
:q!: Quit without saving

Example: Type :wq and press Enter to save and quit.

Visual Mode Commands:

Entering Visual Mode:

v: Start character-wise visual mode
V: Start line-wise visual mode
Ctrl + v: Start block-wise visual mode
Example: Press v to enter character-wise visual mode.

Selecting Text:

Once in visual mode, use arrow keys or navigation commands to select text.
Example: In visual mode, move the cursor to select text.

Copy, Cut, and Paste in Visual Mode:

After selecting text in visual mode, press y to copy (yy for the whole line), d to cut, and p to paste.

Example: In visual mode, press y to copy selected text.
-------------------------------------------------------------------------------------------------------------------------------


IMP COMMANDS 
-------------------------------------------------------------------------------------------------------------------------------
cut : 

The main use of cut command to split/trim the lines in a file.

based on characters/bytes/Delimiter

1 character = 1 byte , same -c or -b 

fields or  Delimiter( Delimiters are characters or sequences of characters used to separate or define boundaries between different pieces of text or data ex: 

Comma (,) Delimiter: Often used to separate items in a list, typically in CSV (Comma-Separated Values) files.

Whitespace Delimiter: Spaces, tabs, or line breaks used to separate words or fields in text data.

Tab (\t) Delimiter: Used to separate columns in tab-delimited files.

Colon (:) Delimiter: Frequently used in configuration files or to separate key-value pairs.

Semicolon (;) Delimiter: Used in CSV files in some regions as an alternative to a comma.

Pipe (|) Delimiter: Often used to separate fields in data files, such as in the context of Unix pipelines.

Hyphen (-) Delimiter: Used in compound words or as a range separator, e.g., "a-b" or "2010-2020."

Underscore (_) Delimiter: Frequently used in variable and function names in programming.

Forward Slash (/) Delimiter: Used in file paths and URLs to separate directories and components.

Backslash (\) Delimiter: Typically used as an escape character in many programming languages and regular expressions.

Hash (#) Delimiter: Often used to denote comments in code or configuration files.

Double Quotation Marks (") Delimiter: Used to enclose strings, especially in CSV files to handle values containing other delimiters.

Apostrophe (') Delimiter: Used to enclose single characters or strings.

Parentheses (()) Delimiter: Used to group expressions in mathematics and programming.

Braces ({}) and Brackets ([]) Delimiters: Used to enclose blocks of code or define arrays and sets in programming.

Angle Brackets (<>) Delimiters: Often used in HTML to enclose tags.

---

cat file1.txt

hello world
hi, jhon 

cut -c 5 file1.txt   ->  ( -c -> character 5 -> 5th character in the line, so it displays the 5th character of eachlines in a file  )

cut -c 1-5 file1.txt  -> it display the character from 1st character to 5th character of  each lines 

cut -c 1,3-5 file1.txt  -> it display the character from 1st character, skip the 2nd character  and take 3rd character to 5th character of  each lines , ( 1st,3rd,4th,5th of each lines in a file)

cut -c 3- file1.txt --> it display the character from 3rd character to last character of  each lines 

cut -c -3 file1.txt --> it display the first 3  characters  of  each lines 

---
delimiter 

1,a,20
2,a,40
3,a,60

cut -c 5 file1.txt

cut -d "," -f1 <filename>  --> it cuts the first column and displays . ( -f -> field/column )

1
2
3

---
1-a-20
2-a-40
3-a-60

cut -d "-" -f1 <filename>
1
2
3

---
1,a,20
2,a,40
3,a,60

cut -d "," -f1-2 <filename>  --> it cuts the first 2 column and displays them , used to cut the range of fields  ( -f -> field/column )

1,a
2,a
3,a
---
root@manjunathachar-k-t:~/bashdemo# ll -h
total 92K
drwxr-xr-x  3 root root 4.0K Oct 22 17:16 ./
drwx------ 19 root root 4.0K Oct 22 17:16 ../
-rwxr-xr-x  1 root root  349 Oct 22 17:16 case1.sh*
-rwxrwxrwx  1 root root  320 Oct 22 17:11 case.sh*
-rw-r--r--  1 root root   83 Oct 11 09:55 file1.txt
-rwxrwxrwx  1 root root  184 Oct 22 13:36 grep.sh*
-rw-r--r--  1 root root   17 Oct 10 10:31 hardlinkorg2.txt
-rw-r--r--  1 root root  162 Oct 22 15:39 mem.txt
drwxr-xr-x  2 root root 4.0K Oct 10 10:07 mywebapp/
-rw-r--r--  1 root root  10K Oct 10 10:08 mywebartifact.tar
-rw-r--r--  1 root root    4 Oct 21 16:30 ouputdir1.txt
-rwxr-xr-x  1 root root  102 Oct 16 10:22 samplearray.sh*
-rwxr-xr-x  1 root root   77 Oct 16 10:25 sampleshell.sh*
lrwxrwxrwx  1 root root    8 Oct 10 10:29 soft2.txt -> org1.txt
lrwxrwxrwx  1 root root    8 Oct 10 10:29 softlink.txt -> org1.txt
-rwxrwxrwx  1 root root 2.7K Oct 21 15:30 tools.sh*
-rw-r--r--  1 root root  688 Oct 20 22:14 unistalltool.sh
-rwxr-xr-x  1 root root   37 Oct 12 10:05 var1.sh*
-rwxrwxrwx  1 root root  123 Oct 12 10:15 var2.sh*
-rwxrwxrwx  1 root root   54 Oct 12 10:28 var3.sh*
-rwxrwxrwx  1 root root   70 Oct 13 09:51 var4.sh*
---x--x--x  1 root root  392 Oct 13 10:01 var5.sh*
-rwxr-xr-x  1 root root  530 Oct 13 10:23 var6.sh*


ll -h | cut -d "," -f6 

ll -h | awk '{print $5, $9}'   --> to display only 6th and 9th fields ) 

ls -h | awk '{printf "%-15s %s\n", $1,$3, $9}'   -->  to display only 5th and 9th fields with proper format using printf ) 

ls -l | awk '{printf "%-15s %-15s %s\n", $1,$3,$9}

ll -h | awk '{printf "%-6s %s\n", $5, $9}'> filesize.txt 

ll -h | awk '{print $6, $9}' |sed '/^$/d'    --> using caret(care-it) ^ $ to remove the spaces or empty lines  among lines in a file 
ll -h | awk '{print $6, $9}' | grep -v ^$   

-------------------------------------------------------------------------------------------------------------------------------

find :

man find

find command is used to search and locate the list of files and dir based on conditions you specify for files that match the arguments. find can be used in a variety of conditions like you can find by permissions, users, groups, file type, date, size , etc ...

You can learn about the find command and its options.


options :
1) -name   --> file1. --> to search a file in any dir and whether the file exist or not in local machine 


2) -iname
3) -type f
4) -type d

--------------------

how this command works 

ex: you want to search a file in your system 

syntax :

find path options 

find   --> this command will list complete path of file and directory in particular dir or system .

find . -name var.sh
options :

1) -name    --> 

find . -name var.sh    --> 

find . -name "*.sh" 

find / -name "*.pem"  

find / -name context.xml 


2) -iname   --> i means  ignore the case sensitive / case insensitive or it considers the uppercase and lower case 

3) -type f   --> to display the regular files 

find . -type f 

----
1. How to find or search  the last( past) 7 days modified files ?

-mtime --> using this argument we list the last modified files 

-  -> To list files modified within the last 7 days (including today), you can use the -mtime option with -7 ( ex : 27 th-20th)

find . -mtime -7


+   -> To list files modified between 7 days and 14 days ago but but not within or the last 7 days,  (e.g., files modified from the 7th day to the 14th day ago) ( ex : 20 th -->  13th)  

find . -mtime +7


2. How to find the last 60 days modifiled files or created files 

find . -mtime -60


3. how to find only hidden regular files 

find . -type f -name '.*'


------
du -> disk usage of file or dir 

df  -> disk usage of file system 


3 ways to find the large file in the system 

1.find /home/manjunathachar -type f -exec du -h {} + | sort -rh | head -n 1     -> to find the largest file in the linux

2.sudo du -h /home | sort -rh | head -n 1   -> to find the largest file in the linux

find /home/manjunathachar -type f -exec du -h {} + | sort -h | head -n 1      -> to find the smallest file in the linux

rm /path/to/folder/*.txt      			 -> Delete files using wildcards (e.g., all files with a specific extension):

3. (NCurses Disk Usage):ncdu - >>> more advanced tool for analyzing disk usage of files/folders on local server . It provides a more interactive and user-friendly way to find large files and directories.

sudo apt-get install ncdu   # For Debian/Ubuntu
sudo yum install ncdu       # For Fedora/CentOS/Red Hat

ncdu /home  
ncdu -e

find . -inum 34872



-------------------------------------------------------------------------------------------------------------------------------
man grep

GREP COMMAND

global regular expression print

basically it searches for a word and print or display the content , according to the option which you have used .

it's going to search a file, content file based pattern 

filter the content of a file

syntax :

grep "searchword" filename

grep is mostly used with piping ( | ).

create file with some content
apple is my favorite
my favorites fruits apple ,mango,durian,
tomato
chilli
grapes
Apple is good for the health
I eat 4 AppleS in a week .


root@manjunathachar-k-t:~/bashdemo# cat grep.sh | grep apple
apple is my favorite
my favorites fruits apple ,mango,durian,
root@manjunathachar-k-t:~/bashdemo# grep apple grep.sh 
apple is my favorite
my favorites fruits apple ,mango,durian,

grep -i "apple" grep.sh    --> to search a words with case insensitive or ignore the case sensitive 

grep -v "apple" grep.sh    ->  to display the words which not matching with "apple"  ,

grep -c "apple" grep.sh     -->  to display the counts of line of the word, 

grep -o "apple" grep.sh   --> to display the match words only ( not  with entire lines ) .

grep -n "apple" grep.sh   --> to display the the words with their line numbers  

grep -A1 "apple" grep.sh   --> to display the specific word line with next line only

grep -B1 "apple" grep.sh   ---> to display the specific word line with previous line 

grep -C3 "apple" grep.sh   ---> to display the specific word line with previous line and next line


===========================================
this command is very important for scripting .

Syntax :

awk ‘BEGIN {start_action} {action} END {stop_action}’ filename


awk '{print }' filename 

ls -l | awk '{print $1 $3}'

let me explain about awk command with simple examples

Example 1:

How to print entire  data of the file

cat filename | awk '{print}'
cat filename | awk '{print$0}'

both "awk '{print}' and awk '{print$0}' " used to print entire data


Example 2:

How to print  very first column

cat filename |  awk '{print$1}'     --> to display the first columns 

awk '{print$1}' filename  --> used to print very first column  
awk '{print$2}' file name -->  used to print second column   --> to print specific multiple columns at a time

awk '{print$2,$3,$4}'   --> used to print 2nd,3rd,4th columns   --> to print specific multiple columns at a time


Example 3:

How to print pattern Matching Technique in Awk.

free -m | awk '/Mem/{print}'   --> to print the Mem row 


here, we are matching Mem using awk '{/Mem/print}'

Example 4:

How to Print multiple column at the time.

free -h | awk '/Mem/{print$1,$2,$4}'    

here, we are print 1st,2nd,3rd columns at the time.

Example 5:

How to Print line number using variable NR

free -h | awk '{print NR,$0}'

Example 6:

How to print specific linesF

free -h | awk '{print NR,$0}'   --> to print the line with system variables ( NR -> Number of records )

free -h | awk 'NR==1,NR==2 {print NR,$0}'   --> to print the lines from line1 to  line3 with variables 

Here,we are print lines between 1 & 2.

Real time

ll -lrth | awk '{print$9}'       --> to print the specific columns of files ( l- list ,r- reverse , t- time , h- human readable )

ll -lrth | awk '{print$1,$9}'  -->  to print the specific columns of files and their permission ( l- list ,r- reverse , t- time , h- human readable                       

Filter data manipulation

cat listofusers.txt | awk '$4~/M/'


cat listofusers.txt | awk '{print NF}'    -> This command prints the value of the last field in each line.


cat listofusers.txt | awk '{print (NF-1)}' //second last coloum in a file 


Soft Links (Symbolic Links) and Hard Links:


/bin/ -> /home/  




Soft Links (Symbolic Links):

Soft links have different inode numbers because they are essentially separate files that point to the target file's path. They are symbolic references.

1. Managing Configurations:

Use soft links to manage configuration files centrally. For example, you have a common configuration file for an application, and each deployment environment requires a slightly different configuration. You can create soft links to the common configuration file in each environment.


ln -s /path/to/common/config.conf /path/to/environment/config.conf

2. Versioning and Rollbacks:

Soft links can be used in versioning and rollback scenarios. For instance, you deploy a new version of your application, and the latest configuration is linked to a specific version. If there are issues, rolling back involves switching the soft link back to the previous version.
bash

ln -s /path/to/versions/v2.0/config.conf /path/to/current/config.conf

3. Dependency Management:

When working with software dependencies, you might use soft links to manage libraries or modules. For example, a deployment might require a specific version of a library, and a soft link can be created to the appropriate version.

ln -s /path/to/libraries/libv1.2.so /path/to/application/lib/lib.so

----

Hard Links:

Hard links, on the other hand, share the same inode number with the original file. They reference the same data blocks on the disk, and changes made to one file are reflected in all files linked to the same inode.


1. Efficient Data Backups:

Hard links can be useful for creating efficient backups. Instead of duplicating entire files, hard links can be created to the existing files. This ensures that changes to one file are reflected in the other, while saving storage space.

ln /path/to/source/file.txt /path/to/backup/file_backup.txt


2. Shared Log Files:

In a distributed system where multiple components need to write to the same log file, hard links can be used to share the same physical file on disk, providing a unified log view.

ln /var/log/application.log /var/log/component1.log
ln /var/log/application.log /var/log/component2.log

3. Managing Identical Content:

Hard links are useful when you have multiple instances of identical files across your system. Instead of having multiple copies, hard links allow different filenames to point to the same data blocks.

ln /path/to/common/file.txt /path/to/another/location/file_alias.txt

-----

softlink and hardlink files


ls -i file1 file2     -> to get  i nodes for particular files 

find . -inum 12345 -delete    -> deleting files using i node values 



org1.txt

ln -s org1.txt softlink.txt        -> to create soft link for org1.txt, as soon as u delete the org1 file , softlink file also be  deleted automatically

org2.txt

ln org2.txt hardlink.txt             -> to create hardlink for org2.txt, as soon as u delete the org2 file and hard link will be remain same, it's link copy of org2 file and used for back up for secretes 

----
cronjob

A cron job is a scheduled task or command that runs automatically at specified intervals on a Unix or Unix-like system, such as Linux. It is used for automating repetitive tasks, such as backups, updates, and maintenance.


Crontab:It is used to Schedule jobs.

Crontab –l: -l is used to List out the job for current user.

Crontab –e:-e is used to edit schedule jobs for current user. 

Crontab –r:-r is used to remove all job for current user.      -> note : Don't try this command until unless remove jobs.

Crontab –e –u <Username> : It is used to edit jobs for particular user. 


Cat /etc/crontab : It used to check cron job info.

*/1 * * *  * /root/cpu.sh >> output.txt   

   *             *               *                    *            *
Minute         Hour         Day of month             Month      Day of week  
(0 - 59)     (0 - 23)         (1 - 31)              (1 - 12)     (0 -6 ) ( sun =0 or 7)
 
 
# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  . ------- month (1 - 12) OR Jan, feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR 
# |  |  |  |  |
# *  *  *  *  *    -> time pattern 

Be practice below examples which are very useful in real time environment.

*/1 – Every one minute 
*/1-   Every one hour
1-31 Day of the month
1-12(Jan to Dec)
0-6(Sunday to Monday) 0Sunday, 1Monday, 2Thesday


*  *   * * *    -> for every minutes
0  *   * * *    -> for every hour 0th min
0 12   * * *    -> @12 pm(noon) every day
0  0   8 * *    ->  every month 8th day
0  3   * * 0    ->  Every sunday
0 7-18 * * *    ->  b/w 7am to 6 pm
0 5,8,12 * * *  ->  @5,8,12 
*/5 * * * *    -> every 5 min interval 

Every day 7-18
* 7-18 * * *  /root/cpu.sh 

Every month 15,16 dates
* * 15,16 * *  /root/cpu.sh 

6 Month one time only
* * * 6 *  /root/cpu.sh 
Every Tues day
* * * * 2  /root/cpu.sh 

0

Scheduled Script Execution:  -> Running a script periodically.

# Edit the crontab
crontab -e

# Run a script every day at 2 AM
0 2 * * * /path/to/script.sh


System Updates:   ->  Automatically updating the system or packages.

# Update system packages every Sunday at 3 AM
0 3 * * 0 yum update -y

Backup Database:  -> Scheduled backup of a database.

# Backup MySQL database every day at 1 AM
0 1 * * * /path/to/mysqldump -u username -p password dbname > /path/to/backup.sql

Cleanup Temporary Files:  -> Cleaning up temporary files.

# Cleanup temp files every week on Sunday at 4 AM
0 4 * * 0 find /path/to/temp -type f -mtime +7 -exec rm {} \;


ex:

=============
useradd -m -d /home/devopsadmin devopsadmin

passwd devopsadmin

su - devopsadmin

ssh-keygen    

ls ~/.ssh 

#You should see following two files:

#id_rsa - private key
#id_rsa.pub - public

cd /home/devopsadmin/.ssh

cat id_rsa.pub > authorized_keys

chown -R devopsadmin /home/devopsadmin/.ssh
chmod 600 /home/devopsadmin/.ssh/authorized_keys
chmod 700 /home/devopsadmin/.ssh

#make devopsadmin user as a owner to tomcat dir :

chown -R devopsadmin /opt/tomcat


=============

BASH SCRIPTING : 


COMMENTS :

usually , used to describe the functions in the script.


#!/bin/bash

# author name : 
# date 
# description

# updating the system
sudo apt-get update -y 

# installing git
#sudo apt-get install git -y








ex : add () {
...
....
}
if you share the same script to someone with comment , how can they understand , to make it understandable about the funtions, where we use comments


types of comments, any language has 2 types of comments except java

2 types
single line comment
multi line comment

in java
//  s l c 

/*

first line code
second line code
third line code 
int a = 23

...   m l c
*/

documentation related comments

/**
....
....
....   
*/

c/c++/sh

# --> s l c in shell script

<<stringname
.....  
.....
.....
stringname
--------
<<Manju
...          m l c in shell script, HERE DOCUMENT FEAUTURE 
Manju

------
in bash script 
in xml file

# -> s l c 
<!--
........    m l c 
........
-->




in groovy file -> jenkins file 

//  -> s l c 

/*


*/


in yaml file


# 





comments are used to escape from the code 
this part of the code will be ignored by the program interpreter
adding comments make things easy for the programmer, while editing the code in future

single line comment can be do using #
# this line is commented 

multiline comments can be do using HERE DOCUMENT feature as  follows


-------------

VARIABLES :

A Variable is a character, string to which we assign a value. the value assigned could be a number text,filename, device, or any other type of data.

there are 2 types of variable in linux shell script

1. system pre defined variables
2. user defined variables   -> 
3. env variables 

10

in shell script

vim file.sh

var1=10

echo $var1

./file.sh


in python
a=10
print(a)
output : 10

echo $a

SHELL=

echo $SHELL


$var1   -> is to define and display  the value of the variable 





1.system pre defined variables and env 
--------------------------------
command to display the  system defined variables

env

printenv


System Predefined Variables:

$HOME: The home directory of the user.
$USER: The username of the current user.
$PWD: The present working directory.
$SHELL: /bin/bash The path to the shell.
$PATH : usr/bin/


/bin/bash -> echo ls, 

/usr/bin/  git , mvn, 

git add .
git rm 
git commit 

Common Environment Variables for DevOps: -> user defined variables 

$JENKINS_HOME: The Jenkins home directory, where Jenkins stores its configuration and data.
$JAVA_HOME: As seen in the script, it points to the Java installation directory.
$PATH: The search path for executable files.
$AWS_ACCESS_KEY_ID and $AWS_SECRET_ACCESS_KEY: AWS credentials for interacting with AWS services.
$DOCKER_HOST and $DOCKER_CERT_PATH: Variables used for Docker configuration.


how can you store the sensitive credentials of any project on local system

1. set up env variable directly 

2. create .env file , and store the credential 

--------------

myplace=bangalore 


bash program -> it's always going to validate the commands( /bin/bash) and variables( .bashrc and or (.bash_profile or .profile)


there two system configuration files in linux

.bashrc   -
.profile   ( in debian )
.bash_profile ( in fedora )

.bashrc  -> bash resource configuration file -> java,git,jenkins,maven  , 

ls, echo $USER , ./var.sh    ->  

echo $myplace



echo $JAVA_HOME
echo $MAVEN_HOME 

export -> It's a function that used to define the USER DEFINED VARIABLE in .bashrc or .bash_profile 

export JAVA_HOME=/usr/lib/jvm/OpenJDK:11
export MAVEN_HOME=/opt/maven
export myplace=bangalore


.profile ->

# -> root user
$ -> normal user
/ -> root home dir
~ -> /home/manjunathachar  dir 

~/.bashrc
~/.profile

source ~/.bashrc 
source ~/.profile 
 
 
 
VARIABLENAME=VARValue

echo $HISTSIZE
1000

see here, history size is 1000(The value "1000" in the context of HISTSIZE means that your shell (such as Bash) is configured to retain the last 1000 commands you've executed in its command history. This is the maximum number of commands that will be stored in the history list.) by default, is this possible to change size , yes , where we use export command


export function ,

it's a statement , which used to pass enviroment variables to other process

export HISTSIZE=20000
echo $HISTSIZE 

---

MYTEAM=RCB
echo $MYTEAM

printenv MYTEAM

export MYTEAM

printenv BBTEAM

export HISTSIZE=20000,this is for temporary changes, once you reboot the system, it will consider the default 1000, if you want to make it permanently, 

where we use .bashrc or .bash_profile



In Linux, both .bashrc and .bash_profile are configuration files related to the Bash shell, and they play a role in customizing the shell environment for users.

.bashrc: shell -> bash shell( resource or tools ) level configuration 

This file is often referred to as the Bash Resource Configuration file.

It is specific to each user and is usually located in the user's home directory (~/.bashrc).

It is executed every time a new terminal session is started or a new shell is opened.

It typically contains settings and configurations for the Bash shell, such as aliases, prompt configurations, and environment variables.

.bash_profile or .profile    -> system level configuration 

This file is executed when you log in to the system.

It is also specific to each user and is usually located in the user's home directory (~/.bash_profile).

If .bash_profile exists, Bash will execute it and ignore .bashrc during login.

It is commonly used to set environment variables and perform tasks that should only happen once when you log in.

Relationship between .bash_profile and .bashrc:

When you start a login shell (for example, when you log in to the system), .bash_profile is executed.

For non-login shells (such as opening a new terminal window or running a script), Bash will look for and execute .bashrc.


demo.sh   -> #!/bin/bash


etc/profile    -> 

vim .bashrc or .bash_profile

export HISTSIZE=20000

-----------------------------------------------------

in programming language-- data types


int -> -30000 to 33000 it's exact number, short number 
float -> 1.2 it's very short decimal number , 0.1
boolean -> true(1) or false(0)
string  -> "hi, some text"
decimal -> 75656387937579797.098038080929 it's verybig exact decimal 
double -> very big number



2. user defined variables ,( for best practice we use lower case as variable name,u can also upper case )

-----------------------
a = 10
echo $a
output is 10

$variable  -> value of variable

$(name of command) ->  value of linux system pre defined commands (echo cat rm rf  mv cp mkdir)

date= $(date)
echo $a or echo ${a}
w_d= $(pwd)
echo $a
user_id=$(id -u)

user_id=4748484 




How can you assign the predefined command to variable ?


DATE=$(date)    $(name of command)      $(date +%a)  

echo $DATE


name=manjunath

date 

echo 
ls
pwd

a=10
echo $a
echo $date





 

a=$(system defined command) means a=$(date)

echo $a
output is today's date .

user_id=$(id -u ) 
echo $user_id
output is 1000->normal user
output is 0 -> root user




system pre defined commands / env variables / user defined variable /special variables ($#@!?) , $? -> exit status 





it's customized user variabls,

ex: int data type

in c/cpp/java

declaring the variables
int a;
int b;
int c;

a=10

str


initialisation the variables,( creating and assigning the value to variables )
int a = 10;
int b = 20;
int c = 30;



in shell script there is no data type in shell script like this 

in shell script

a=10  ( there is no space between variable name and value ) 
b=34
c=45

echo $a or echo ${a}

a=10
b=20
c=30
b=23

echo $a
echo $b 
echo $c
echo $b

---
manjunathachar@manjunathachar-k-t:~/linuxdemo$ ./ee.sh 
10
23
30
23
---
manjunathachar@manjunathachar-k-t:~/linuxdemo$ cat ee.sh 
a=10
b=20
c=30
b= 23
echo $a
echo $b 
echo $c
echo $b
--------------
shell script override the values ,will consider last one 

if you want to print with some message

echo "the value of c is : $c"

============================================ 

let's use system defined ( can we use system defined variables in shell script, yes we can )


echo "the username is : $USER "
echo " the shell name is : $SHELL "



---
manjunathachar@manjunathachar-k-t:~/linuxdemo$ ./sysvariable.sh 
the username is : manjunathachar 
 the shell name is : /bin/bash 
---
============================


can i assign the user defined variable to system defined variable , YES I CAN 

whenever you are going to assign system defined variables or env variables and pre defined commands , you have to use $ sign as prefix  

DATE=$(date)   -> assigning the value of system defined command to user defined variable
name=$USER     -> assigning the value of env variable to user defined variable
place=bangalore ->  assigning a normal value  to user defined variable





echo "${name}"

==================================


1. how can you directly  create varibales and assign the values inside the shell scripting ?


#!/bin/bash

NAME=Ramesh          #don't give a space 
echo "hi, ${NAME}"   # $NAME OR ${NAME} This is comment

NAME="Ramesh"
echo ${NAME}


bash var1.sh
sh var1.sh
./var1.sh  


2. how can you run  a command inside the shell script and get the value inside the variable ?


date: 08/02/2024 , 08-02-2024 ,



#!/bin/bash

DATE=$(date +%F)    # syntax is DATE=$(name of command)

DATE=$(date +%a)
DATE=$(date +%A%B)
DATE=$(date +%b)
DATE=$(date +%B)
DATE=$(date +%c)
DATE=$(date +%C)

       %%     a literal %

       %a     locale's abbreviated weekday name (e.g., Sun)

       %A     locale's full weekday name (e.g., Sunday)

       %b     locale's abbreviated month name (e.g., Jan)

       %B     locale's full month name (e.g., January)

       %c     locale's date and time (e.g., Thu Mar  3 23:05:25 2005)

       %C     century; like %Y, except omit last two digits (e.g., 20)

       %d     day of month (e.g., 01)

       %D     date; same as %m/%d/%y

       %e     day of month, space padded; same as %_d

       %F     full date; like %+4Y-%m-%d



echo "today's date is ${DATE}"


date 

DATE=date -> assigning the value to DATE variable
DATE=$(date)   -> assigning the value of command to DATE variable


how can you assign system predefined command to user defined variable ?

DATE=$(date)


id -u 

USER=$(id-u)

echo $USER    -> 

------------------------------

COMMAND LINE ARGUMENTS(values)
----------------------

During shell script execution, values passing through command prompt is called as command line arguments


variable_name=value for the variable
key=arg
name="Jhon"   -> hard coding 
name="$1" 


passing the values during the bash script execution  -> ./scriptname.sh 

for ex:

while running a shell script , we can specify the command line arguments as "shell scriptfile.sh arg1 arg2 arg3


While using command line arguments follow the below important points

we can specify n number of arguments , there is no limitation.

each argument is separated by space .


ex: i have a dbbackup.sh ,this file is for backup of your database, 

earlier we used to do hard coding in script , 

requirement, 

you have different databases, want to store to some location . 

./dbbackup.sh dbname dbloc


$0 -- shell script name
$1 --. first arg
$2  --> 2nd arg
$3   --> 3rd arg --> if there is no value for arg, it wont diplay anything.
$20
echo ${20}  --> if u want to get particular arg, and if it's morethan one digit, use curly braces  

how to get number of arg :


./sample.sh arg1 arg2 

in script

echo $#  --> to get number of args    
echo $*  --> to  o display the all the arguments as single string 

echo $@ --> to display the all the arguments as individual string 


echo $$ --> to display the process ids(PIDS)

echo $? (imp)--> to display the previous command execution status or exit status (  1 to 127 standard error code for 	) 

----


3. How can you pass the values to the shell script from outside through args/arguments.( it's another way of passing values to the variables)


$0,$1,$#,$$,$?,$*,$@

 hi ramesh Good morning


in shell script: values take like ramesh($1), suresh($2), sachin($3)
		          
		          
		          
		          
i want output like hi John  Good morning -----> (./v3.sh ramesh morning)

#!/bin/bash
NAME=$1
WISH=$2

echo "hi, ${NAME} Good ${WISH}"

------------------
vim clargs.sh  john bangalore 25 

#!/bin/bash

echo "c l args demo"
echo "script file name : $0"
echo "first arg : $1"
echo "Second Arg : $2"
echo "3rd arg : $3"
echo "10th arg : ${10}"
echo "number of args : $#"
echo "All the args : $*"
echo "All the args : $@"
echo "pids : $$"
echo "previous cmd execution status : $?" 




=================================================================================================


4 .how can you ask user to enter the values dynamically . i.e. read command 

user input or user prompt 


echo "Enter your Pin"   5758
read PIN     -> INVISIBLE
echo "select your bank account"
read YOUR_BANK_ACCOUNT_TYPE    -> Saving bank
echo "Enter the amount"
read YOUR AMOUNT     -> VISIBLE 






ex: running a script that connect to DB , where it asks username and password

#!/bin/bash
echo "please enter your name"
read -s USERNAME                             #(if you don't use -s, it will show user name while user entering his name , people can see while he is entering , that's y where we use -s to hide  user name while user entering his user name )
echo "user name is : ${USERNAME}"        # here echo command no need to use for user , because it displays the user name 
echo "please enter your password"
read -s PASSWORD
echo "password is : ${PASSWORD}"         # here echo command is not recommanded to use for password , because it displays the password name

==================================================================================================================================

array -> list of elements or a group of same type of variables 

element -> object,aspect , thing,

forward indexing -> 0th element
backward indexing -> -1 
0th value



ex :                Fruits = apple , banana , orange, mango, ( here we count element with indexing i .e begins with  0th element as first element ) 

forward indexing              0        1        2     3  

backword indexing            -4       -3       -2    -1

                
   forward indexing   -> begins with left to right  -> start with 0th element       
   backword indexing  -> begins with right to left  -> start with -1th element 

sudo vim array.sh
#!/bin/bash
FRUITS=("apple" "banana" "orange" "mango")    # array should be separated by spaces not COMMAS .
echo "fruits at 0th element is : ${FRUITS[0]}"

----------------------------------------------------------------------------------------------------------------------------------

ARITHMETIC OPERATIONS
---------------------------


+
_

*
/

`expr opt1 + opt2`
`expr 2 + 5`



a=2
b=3
c=a+b
echo $c






we use the keyword "expr" to perform arithmetic operations . 


syntax:

`expr op1 math-operator op2`





FileName: arithmetic_operation.sh

`expr 3 + 2`   Addition:
expr 3 - 2   Subtraction:
expr 10 / 2   Division:
expr 3/* 2  --> we use / it's a escape character ,  Multiplication:   * wild card 
expr 20 % 3  --> Modulus (Remainder): it's modular operator, it gives reminder , if it's not divisible by exact number.


echo additon of 3 and 2 is : `expr 3 + 2`

Note : there must be spaces between the operations and the expression.

for example: 3+2 is not correct

it should be written as 3 + 2

complete expression should be enclosed between ``, called the inverted commas,(two backticks)

echo " the addition of 2 and 3 :   expr 2 + 3 " ❌️ --> it's going to print as it as , wont get result 
echo " the addition of 2 and 3 : 'expr 2 + 3' " ❌️ --> it's going to print as it as , wont get result 
echo " the addition of 2 and 3 : `expr 2 + 3` " ✅️ --> using this one , will get result as u expected

-----
vim argops.sh

expr 3 + 2 
expr 3 - 2
expr 10 / 2
expr 3/* 2  
expr 20 % 3 


write a shellscript to accept the 2 numbers from the user and perform the aruguments operators

./argops.sh 34 54 

expr $1 + $2
expr 3 - 2
expr 10 / 2

===============

comparison operators / hints/clue for operators:

= -> to assign the value to variable 



ex: a=10



-eq -> equal to    -> $a -eq 10   -> True
-gt -> greater than -> $a -gt 10  -> False
-lt -> lesser than  -> $a -lt  10 -> False
-ge  -> greaterThan  or equal to   -> $a -ge 10  -> True 
-le  -> lesserThan or equal to     -> $a -le 10  -> True 


-eq  --> ==  --> equal to 
-ne  --> !=  --> not equal to 
-lt  --> <   --> lesser than
-gt  --> >   --> greater than
-le  --> <=  --> lesser than or equal to 
-ge  --> >=  --> greater than or equal to 
--------------------------------------

#!/bin/bash

echo "hi"
pwd
ls


echo "hello'

echo "good morning"



which command is used to get previous command execution status ??

$0  -> 
$# 
$? -> exit code status  -> 1 to 127 ( failure )  , 0 ( success code )


control statement ?






unfortunately shell don't care the error it will just move forward whether the command is correct or not , ultimately consider the last command 


so , it's our responsibility to check the commands are executed successfully or not

$? -- > (exit code ) 0 is success, if morethan 0 is failure (1 to 127)
$? -> previous command execution status , 

if execution is failed -> status would be between 1 to 127
if execution is succeed -> status would be 0

statements -> executable instructions , 

-------

CONTROL FLOW STATEMENTS :

simple if 
if else
if elif 
nested if 

loop
 for loop
 while loop
 
switch cases
functions



simple if condition

function_name() {


}
        
to express any condition , you must have atleast one variable 

if [expression] ;
then
these commands run when expression is true 
fi


--------------------

USER_ID=$(id -u)

if [ $USER_ID -eq 0 ] ;
then
echo "user has root access"

fi 


========

there are two different way to pass the value to variable dynamically 

1. using command line arg   ./scriptname.sh  arg1
2. using read command  
a. 
echo "enter a number "
read number

if [ $number -ge 20]

--
b.

read -p " enter a number " number

if [$number -ge 20]



#!/bin/bash

read -p "Enter a number: " num

# Simple if condition
if [ $number -gt 10 ]; then
    echo "The number is greater than zero."
fi




if (expression) {
 sudo yum install git -y
} 

id -u -> normal user -> 1000
id -u -> root user -> 0

-eq -> equal to 
-gt -> greater than
-lt  -> lesser than
-ge  -> greaterThan or equal to 
-le  -> lesserThan or equal to 


USER=$(id -u)

if [$USER -eq 0] 
 then 
  echo "congrats, you have root access you can proceed"
  
fi

switch cases:
case 
esac





if the expression is false the function is not run at all 

-----------------------------------------------------------------

1. Simple if-else script:

#!/bin/bash

read -p "Enter a number: " num

if [ $num -gt 10 ]; then
  echo "The number is greater than 10."
else
  echo "The number is not greater than 10."
fi


Explanation:

This script takes a number as input from the user.
It checks if the number is greater than 10.
If the number is greater, it prints "The number is greater than 10." Otherwise, it prints "The number is not greater than 10."

=================================================================================================================================
if else function

Simple if-else script:

Purpose: It helps the computer make a decision based on whether a condition is true or false. If the condition is true, one action is taken; if false, another action is taken.

Real-time example: Think of a traffic light. If the traffic light is green, you can go (condition is true), but if it's red, you must stop (condition is false).


if (expression) {
these commands run when expression is true 
} 
else {
these commands run when expression is false
}



if (exit code is 0 ) {
then print successfully installed
}
else{
then print failure
} 
------------


conditions :

write a script to pass only two args 

system pre defined argument or special varibles 
$0
$1
$2
$# -> no.of agrs
$? -> previous command execution status
$@ -> name of args
@* -> name of args 




if [ $# -eq 2 ] then

echo " this is my first args : $1 "
echo " this is my second args : $2 "
echo " this is my 3rd args : $3 "

else

echo "please pass exact two args"
echo " Usage : ex:  bash $0  manju achar 

fi



if [ $# -eq 2 ]
then 
echo "c l args demo"
echo "script file name : $0"
echo "first arg : $1"
echo "Second Arg : $2"
echo "3rd arg : $3"
echo "10th arg : ${10}"
echo "number of args : $#"
echo "All the args : $*"
echo "All the args : $@"
echo "pids : $$"
echo "previous cmd execution status : $?"
else
echo "you shoudl pass the 2 args.."
echo "usage : sh $0 dbname dbbloc"

fi

-----------

java --version

if [ $? -eq 0 ]
then 
echo "java already installed"
echo "installing the maven...."
else
echo "java is not installed.."
echo "install the java first then install the maven"

fi 

==================




3. If-elif :   -> if with multiple else condtions 

If-elif script:

this is used when you have multiple conditions to check , and you want the computer to choose the first condition that's true, and execute the corresponding actions


if elif -> it has single main /outer condition with multiple options 


#!/bin/bash

read -p "Enter age: " age

if [ "$age" -le 18 ];    # space needed before the closing square bracket
then
  echo " the ticket price is Rs. 250."
elif [ "$age" -ge 19 ] && [ "$age" -le 60 ];  # space needed before and after square brackets

then
  echo "the ticket price is Rs. 350."
else
  echo "the ticket price is Rs. 200."
fi

--------------------



#!/bin/bash
read -p "Enter a age: " age

if [ $age -gt 18 ]; then
  echo "the person is adult."
elif [ $age -eq 18 ]; then
  echo "the person is senior citizen."
else
  echo "The person is not adult."
fi




Explanation:

This script also takes a number as input.
It checks if the number is greater than 10. If yes, it prints "The number is greater than 10."
If the number is not greater than 10, it checks if it's equal to 10. If yes, it prints "The number is equal to 10."
If it's neither greater than 10 nor equal to 10, it prints "The number is less than 10."
-----------

EXAMPLE :3 for if elif 


#!/bin/bash

echo "Welcome to the deployment script!"

echo "Which environment are you deploying to? (dev, staging, prod)"
read environment

if [ "$environment" == "dev" ]; then
    echo "Deploying to dev environment..."
    
    # Additional commands for deploying to dev
    
elif [ "$environment" == "staging" ]; then
    echo "Deploying to staging environment..."
    
    # Additional commands for deploying to staging
    
elif [ "$environment" == "prod" ]; then
    echo "Deploying to production environment..."
    
    # Additional commands for deploying to production
else
    echo "Invalid environment specified!"
fi


----------------------

4.nested if  --> multiple if statements can be nested with in if statements .

when you have conditions within conditions, like making more specific decisions based on previous decisions

if it's with in budget( outer condition), if it's, if  it has good milege ( inner condition1), and if it's  safe model ( inner condition2), if both these conditions are true , you decide to buy it 


purpose: It's used when you have conditions within conditions, like making more specific decisions based on previous decisions.

Real-time example: Imagine you're buying a car. First, you check if it's within your budget (outer condition). If it is, you check if it has good mileage (inner condition 1) and if it's a safe model (inner condition 2). If both these conditions are true, you decide to buy it.

EXAMPLE: 1

#!/bin/bash

read -p "Enter your age: " age

if [ $age -ge 18 ]; then
  echo "You are an adult."
  if [ $age -ge 65 ]; then
    echo "You are a senior citizen."
  else
    echo "You are not a senior citizen."
  fi
else
  echo "You are not an adult."
fi

Explanation:

This script takes your age as input.

It first checks if you are 18 years or older. If yes, it prints "You are an adult."
If you are an adult, it further checks if you are 65 years or older. If yes, it prints "You are a senior citizen."
If you are an adult but not 65 or older, it prints "You are not a senior citizen."
If you are not 18 or older, it prints "You are not an adult."
These scripts showcase the use of if-else statements and nested if-else statements to make decisions and execute different actions based on conditions.

==========

# !/bin/bash

if [ $# -ne 1 ]
then
        echo "You need to enter the year."
        exit 1
fi

year=$1

if [ $[$year % 400] -eq "0" ]
then
        echo "$year is a leap year!"
elif [ $[$year % 4] -eq 0 ]
then
        if [ $[$year % 100] -ne 0 ]
        then
                echo "$year is a leap year!"
        else
                echo "$year is not a leap year."
        fi
else
        echo "$year is not a leap year."
fi


*********************************************************

# !/bin/bash
Balance=900
if ((Balance < 0)); then
  echo "Balance is less than zero, Please add more funds else you will be charged penalty"
elif ((Balance == 0)); then
  echo "Balance is zero, please add funds"
else
  echo "Your balance is above zero."
fi


*********************************************************

#!/bin/bash
read -p "Enter theory marks: " quiz_marks
read -p "Enter practical marks: " assignments_marks
if (($quiz_marks > 50));
then
  echo "Please check the input marks for quiz."
elif (($assignments_marks > 50));
then
  echo "Please check the input marks for assignments."
else
  echo " Your total marks: sum=$(( quiz_marks + assignments_marks))"
fi


*********************************************************
Loops are used in any programming language to execute the same code repeatedly. Three types of loops are mainly used in programming for doing repetitive tasks. These are for, while, and do-while/repeat-until loop. You can apply for loop on bash script in various ways. Some useful BASH for loop examples has been mentioned in this article.

Syntax of for loop:

# loop through a list
for value in list
do
    commands
done

# loop specified values
for value in file1 file2 file3
do
    commands
done

# loop through strings resulting from a command
for value in $(Linux command)
do
    commands
done

# loop through increment or decrement numbers
# traditional procedural for loop
for (( i=0; i<10; i++)
do
    commands
done

According to the above syntax, the starting and ending block of for loop is defined by do and done keywords in the bash script.

Example-1: Reading static values
Create a bash file named loop1.sh with the following script to read the values from a list using for loop. In this example, 5 static values are declared in the lists. This loop will iterate 5 times, and each time, it will receive a value from the lists and store it in the variable named color that will print inside the loop.


#!/bin/bash
# Define loop to read string values
for color in Blue Green Pink White Red
do
    # Print the string value
    echo "Color = $color"
done


Example-2: Reading Array Variable

You can use for loop to iterate the values of an array. Create a new bash file named loop2.sh with the following script. In this example, the loop retrieves the values from an array variable named ColorList, and it will print the output only if the Pink value is found in the array elements.


#!/bin/bash
# Declare and array
ColorList=("Blue Green Pink White Red")
# Define loop to  iterate the array values
for color in $ColorList
do
    # Check the value is pink or not
    if [ $color == 'Pink' ]
    then
            echo "My favorite color is $color"
    fi
done



Example-3: Reading Command-line arguments

Command-line arguments values can be iterated by using for loop in bash. Create a new bash file named loop3.sh with the following script to read and print the command-line argument values using for loop.

#!/bin/bash
# Define loop to read argument values
for myval in $*
do
    # Print each argument
    echo "Argument: $myval"
done




Example-4: Finding odd and even number using three expressions

The C-style syntax of for loop is three expression syntax. The first expression indicates initialization, the second expression indicates termination condition, and the third expression indicates increment or decrement. Create a bash file named loop4.sh with the following script to find out the odd and even numbers from 1 to 5.


#!/bin/bash

# Define for loop in C-style format
for (( n=1; n<=5; n++ ))
do  
    # Check the number is even or not
    if (( $n%2==0 ))
    then
        echo "$n is even"
    else
        echo "$n is odd"
    fi  
done

=,-,/,* = %


Example-5: Reading file content

You can use for loop to read the content of any file by using the ‘cat’ command. Suppose you have a file named ‘weekday.txt‘ which contains the name of all weekdays. Now, create a bash file named loop5.sh to read and print the content of the file.

#!/bin/bash
# Initialize the counter
i=1
# Define for loop to read the text file
for var in `cat weekday.txt`
do
    # Print the file content
    echo "Weekday $i: $var"
    ((i++))
done


Example-6: Create infinite for loop

Create a bash named loop6.bash with the following script to know the way to declare infinite for loop. Here, the loop will iterate for infinite times and print the counter value until the user presses Ctrl+C.

#!/bin/bash
# Initialize counter variable
counter=1
# Display message for termination
echo "Press Ctrl+c to terminate from the loop"
# Define infinite loop
for (( ;; ))
do
   # Print the number of iteration
   echo "Iterating for $counter time(s)."
   # Wait for 1 second
   sleep 1
   # Increment the counter
   ((counter++))
done



Example-7: Use of for loop with command substitute

Create a bash file named loop7.bash with the following script to know the use of for loop to read and print the command output.

#!/bin/bash
echo "All bash files starting with 'a' are:"

# Read the output of command substitute using for loop
for val in $(ls a*.bash)
do
    # Print the file name
    echo "$val"
done


Example-8: Conditional exit with break

Create a bash file named loop8.bash with the following script to know the way to exit from the loop based on any particular condition.

#!/bin/bash
# Define a for loop to iterate 10 times
for (( i=1; i<=10; i++ ))
do  
    # Define the conditions to terminate the loop
    if (( $i%3==0 && $i%6==0 ))
    then
        # Terminate from the loop
        echo "Terminated."
        break
    else
        # Print the current value of i
        echo "The current value of i is: $i"
    fi  
done

Example-9: Early continuation with continue statement

Create a bash file named loop8.bash with the following script to know how to omit one or more statement(s) from the loop by using a continuous statement based on the particular condition.

#!/bin/bash
# Declare an associative array
declare -A Applicants
# Intialize the array values
Applicants=( [1022]="Present" [1034]="Present" [1045]="Absent" [1067]="Present" )

echo "List of the applicant's ID who are present:"
for k in ${!Applicants[@]}
do
     # Filter the applicant's ID who are absent
     if [ ${Applicants[$k]} == "Absent" ]; then
        continue
     else
        # Print the applicant's ID who are present
        echo $k
     fi
done


echo "enter number"
read num
function prime
{
for((i=2; i<=num/2; i++))
do
  if [ $((num%i)) -eq 0 ]
  then
    echo "$num is not a prime number."
    exit
  fi
done
echo "$num is a prime number."
}
r=`prime $number`
echo "$r"



=================================================================================================================================

EXPLAIN THE FREE COMMAND 


As a DevOps engineer, your role involves optimizing the performance and reliability of systems while ensuring smooth deployment and operation of software applications. Let's see how cache memory and swap memory are relevant from a DevOps perspective:

Cache Memory:

Purpose: Utilizing cache memory effectively can significantly enhance the performance of applications and services deployed on your infrastructure. It helps reduce latency by storing frequently accessed data closer to the CPU, minimizing the need to retrieve it from slower storage devices.

Example: Consider a DevOps engineer responsible for managing a microservices-based architecture. By configuring caching mechanisms within the application stack, such as using Redis or Memcached, you can speed up data retrieval and reduce the load on backend databases. This not only improves application performance but also optimizes resource utilization across your infrastructure, leading to better scalability and cost-effectiveness.

Swap Memory:

Purpose: Swap memory plays a critical role in maintaining system stability and ensuring uninterrupted operation, especially during periods of high resource demand or unexpected spikes in traffic. Effective management of swap space can prevent out-of-memory issues and mitigate the risk of application failures due to memory exhaustion.

Example: As a DevOps engineer, you may encounter scenarios where certain applications or services experience sudden surges in memory consumption, potentially leading to performance degradation or system crashes. By monitoring swap usage metrics and implementing proactive measures, such as optimizing resource allocation, scaling infrastructure resources, or fine-tuning application configurations, you can preemptively address memory-related bottlenecks and maintain reliable service delivery.

In summary, as a DevOps engineer, understanding the role of cache memory and swap memory is essential for optimizing system
performance, enhancing application reliability, and effectively managing resources across your infrastructure to meet the demands of modern, dynamic environments.














  
